# 2026 Session Schedule (Biweekly Wednesdays)

Cadence: every two weeks on Wednesdays, starting **2026-03-04**.

Breaks:

- August 2026: no sessions (summer break)
- Holidays: if a session falls on a holiday, skip that week and meet the following Wednesday

| # | Date (Wed) | Paper | Notes |
| --- | --- | --- | --- |
| 1 | 2026-03-04 | Neural Machine Translation of Rare Words with Subword Units (2015) | `sessions/2026-03-04-bpe.md` |
| 2 | 2026-03-18 | Attention Is All You Need (2017) | `sessions/2026-03-18-transformer.md` |
| 3 | 2026-04-01 | What Does BERT Look At? An Analysis of BERT's Attention (2019) | `sessions/2026-04-01-bert-attention.md` |
| 4 | 2026-04-15 | Attention is not Explanation (2019) | `sessions/2026-04-15-attention-not-explanation.md` |
| 5 | 2026-04-29 | Transformer Feed-Forward Layers Are Key-Value Memories (2020) | `sessions/2026-04-29-ffn-kv-memory.md` |
| 6 | 2026-05-13 | The Curious Case of Neural Text Degeneration (2019) | `sessions/2026-05-13-text-degeneration.md` |
| 7 | 2026-05-27 | Datasheets for Datasets (2018) | `sessions/2026-05-27-datasheets.md` |
| 8 | 2026-06-10 | FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness (2022) | `sessions/2026-06-10-flashattention.md` |
| 9 | 2026-06-24 | LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale (2022) | `sessions/2026-06-24-llm-int8.md` |
| 10 | 2026-07-08 | LoRA: Low-Rank Adaptation of Large Language Models (2021) | `sessions/2026-07-08-lora.md` |
| 11 | 2026-07-22 | QLoRA: Efficient Finetuning of Quantized LLMs (2023) | `sessions/2026-07-22-qlora.md` |
|  | 2026-08-05 | No session (August break) |  |
|  | 2026-08-19 | No session (August break) |  |
| 12 | 2026-09-02 | The Flan Collection: Designing Data and Methods for Effective Instruction Tuning (2023) | `sessions/2026-09-02-flan.md` |
| 13 | 2026-09-16 | LIMA: Less Is More for Alignment (2023) | `sessions/2026-09-16-lima.md` |

